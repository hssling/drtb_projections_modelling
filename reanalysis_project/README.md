# TB Drug-Resistance Reanalysis (Reproducible Package)

This folder contains a clean, reproducible reanalysis focused on India’s TB and drug-resistant TB (DR-TB) burden. It addresses earlier gaps by using traceable data sources, explicit assumptions, and transparent modeling steps.

## Data Sources (copied into `data/raw`)
- `worldbank_tb_incidence.csv`: World Bank/WHO TB incidence series (indicator `SH.TBS.INCD`).  
- `national_notifications_2021_2024.csv`: National notifications and deaths (2021–2024) from the provided source file `RS_Session_265_AU_1692_A_to_D.csv`.  
- `state_notifications_2017_2024.csv`: State-level TB notifications (2017–2024) from `tb_notifications_comprehensive_17_24.csv`.  
- `who_mdr_rr_estimates.csv`: WHO MDR/RR-TB burden estimates (2015–2024) copied from `mdr_tb_india_burden.csv`.
- `annual_notifs.csv` and `sub_annual_notifs.csv`: GTB snapshot (2025-07-30) country notification series from `gtbreport2025-main.zip`.  
- `drroutine.csv`/`drret.csv`: GTB routine drug-resistance surveillance outputs (converted from RDA) for cross-checking RR/MDR counts (India slice stored in `data/processed/india_rr_routine.csv`).

## Folder Layout
- `data/raw/` — exact copies of inputs (no edits).  
- `data/processed/` — cleaned/reshaped tables generated by scripts.  
- `scripts/` — analysis scripts (ingest, validation, forecasting, DR burden estimation).  
- `figures/` — generated plots.  
- `reports/` — summary tables (CSV) and evidence notes.  
- `manuscript/` — reanalysis manuscript draft and assets.

## How to Reproduce
1. Ensure Python 3 with `pandas`, `numpy`, `matplotlib`, `seaborn`, `statsmodels`, `scikit-learn`.  
2. From repo root, run:  
   ```bash
   python3 reanalysis_project/scripts/run_reanalysis.py
   ```  
3. Outputs: processed CSVs in `data/processed/`, plots in `figures/`, tables in `reports/`, and manuscript draft in `manuscript/`.

## PubMed Utilities (Optional)
- Retrieve recent India DR-TB/RR-TB abstracts to `reanalysis_project/reports/pubmed_search_results.csv` and extract numeric mentions to:
  - `reanalysis_project/reports/pubmed_percent_mentions.csv` (per PMID: all `%` strings + summary stats + context snippets)
  - `reanalysis_project/reports/pubmed_percent_mentions_summary.csv` (per PMID: count/min/max/mean)
  - `reanalysis_project/reports/pubmed_numeric_mentions.csv` (one row per percent mention, with best-effort `n=`, `x/y`, and CI parsing)
  ```bash
  python3 reanalysis_project/scripts/lit_search_pubmed.py
  ```
- Useful flags:
  - Fetch more results: `--max-total 0` (unlimited) or set a larger `--max-total`.
  - Change date range: `--mindate 2018/01/01 --maxdate 2024/12/31`
  - Control India post-filter: `--india-filter strict|loose|none`
  - Save exclusions + reasons: `--write-excluded` (writes `reanalysis_project/reports/pubmed_excluded.csv`)

## Real Meta-Analysis (Manual Extraction Required)
The PubMed numeric extraction is only for screening; a real meta-analysis needs a structured extraction sheet with study definitions and denominators.

1. Initialize an extraction sheet from the current PubMed list:
   ```bash
   python3 reanalysis_project/scripts/init_meta_extraction.py
   ```
   This writes `reanalysis_project/reports/lit_meta_extraction.csv` (start from `reanalysis_project/reports/meta_extraction_template.csv`).
2. Manually fill `lit_meta_extraction.csv` from full text/tables (at minimum: `included`, `n_total`, `n_resistant`, and consistent `drug_resistance_type` + `new_or_retreatment`).
3. Run the pooled prevalence meta-analysis:
   ```bash
   python3 reanalysis_project/scripts/run_meta_from_extraction.py
   ```
   Output: `reanalysis_project/reports/lit_meta_summary.csv`.

### Optional: Abstract-Based Autofill (Screening Only)
You can generate *suggestions* for `n_total/n_resistant` from abstracts (fractions like `x/y` and `p% (x/y)`), but these must be verified.

```bash
python3 reanalysis_project/scripts/autofill_meta_extraction_from_abstracts.py
python3 reanalysis_project/scripts/apply_autofill_to_extraction.py
python3 reanalysis_project/scripts/run_meta_from_extraction.py --in-csv reanalysis_project/reports/lit_meta_extraction_autofill_applied.csv --out-csv reanalysis_project/reports/lit_meta_summary_autofill.csv --include-auto
```

Notes/caveats: `reanalysis_project/reports/lit_meta_autofill_notes.md`

To prioritize verification, generate a compact review queue from the `included=auto` rows:
```bash
python3 reanalysis_project/scripts/generate_meta_review_queue.py
```
Outputs: `reanalysis_project/reports/lit_meta_review_queue.csv` and `reanalysis_project/reports/lit_meta_review_queue.md`

After you fill the `verified_*` columns in `reanalysis_project/reports/lit_meta_review_queue.csv`, apply updates back to the main sheet:
```bash
python3 reanalysis_project/scripts/apply_review_queue_updates.py
```
Output: `reanalysis_project/reports/lit_meta_extraction_updated.csv`

## Scope & Assumptions
- DR-TB rates blend WHO RR% with GTB RR counts converted to percentages (assumes 87/13 new vs. retreated split for denominators) and apply a linear trend to 2030.  
- State-level DR burden is estimated by distributing national DR rates across state notification volumes (no state-specific RR data available). Results are labeled as modeled estimates, not observations.  
- No fabricated study counts: all figures and tables are derived directly from the raw files above.
